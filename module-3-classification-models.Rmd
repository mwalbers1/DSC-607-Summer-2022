---
title: "DSC 607 Data Mining: Classification using kNN and Decision Trees"

date: "`r Sys.Date()`"

output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

1. Create Decision Tree and KNN classifiers on a data set without cross validation. 

2. Then using cross-validation create classification decision tree and KNN models on same data set.  

Compare results between first two cases:

- Which classifier was more accurate?

- Which strategy performed best? cross-validation or without cross-validation?

- What statistic was used to compare performance


## Data Set

This is an Olympic Games dataset that describes medals and athletes for Tokyo 2020. The data was created from the [2020 Tokyo Olympics](https://olympics.com/tokyo-2020/en/). More than 2,400 medals, and 11,000 athletes (with some personal data: date and place of birth, height, etc.) of the XXXII Olympic Games you can find here. Apart from it coaches and technical officials are present. 

The medals.csv file was downloaded from [Kaggle](https://www.kaggle.com/datasets/piterfm/tokyo-2020-olympics?select=medals.csv)

**Author of Data Set:**

Petro
Kaggle Expert
Lviv, Lviv Oblast, Ukraine
Data Scientist, PhD

## R Libraries

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(skimr)
library(janitor)
```
```{r echo=FALSE, warning=FALSE, message=FALSE}
library(class)
library(caret)
library(rpart)
```

```{r lessR library, echo=FALSE, warning=FALSE, message=FALSE}
library(lessR)
```

## Read CSV file

```{r}
medals_data <- read.csv('data/medals.csv')
```

```{r}
str(medals_data)
```

## Data Cleaning

```{r}
skim_without_charts(medals_data)
```

```{r}
medals_data_trimmed <- medals_data %>% 
  select(medal_type, athlete_short_name, athlete_sex, country_code, country, discipline_code, event)
```

```{r}
head(medals_data_trimmed)
```
```{r glimpse medals data trimmed}
glimpse(medals_data_trimmed)
```


### Display proportion of medal types


```{r donut chart of medal types}
PieChart(x = medal_type, data = medals_data_trimmed, values="%", main = "Olympic Medals")
```
This donut chart shows an equal proportion of medal types for Gold, Silver and Bronze medals


## Check for Outliers

```{r contigency table discipline_code}
discipline_code_freq <- table(medals_data_trimmed$discipline_code) %>% as.data.frame %>% arrange(Freq)
```

```{r}
distinct_discipline <- medals_data %>% 
  select(c(discipline_code, discipline)) %>% 
  unique()
```

```{r}
discipline_freq <- merge(discipline_code_freq, distinct_discipline, by.x = 'Var1', by.y = 'discipline_code', all.x = TRUE) %>% 
  arrange(Freq)
```

```{r}
discipline_freq <- clean_names(discipline_freq)
```

```{r}
discipline_freq_new <- discipline_freq %>% 
  select(var1, freq, discipline) %>% 
  rename(var1, discipline_code) %>% 
  rename(freq, frequency)
```


```{r}
discipline_freq_new
```

```{r histogram for discipline_freq_new}
ggplot(data = discipline_freq_new) +
  geom_histogram(mapping = aes(x=frequency), bins = 50, color="white", fill="purple") +
  scale_x_continuous(breaks = seq(min(discipline_freq_new$frequency), max(discipline_freq_new$frequency), by = 15)) +
  scale_y_continuous(breaks = seq(1, 15, by=2)) +
  labs(title="Discipline Frequency",
       x="Frequency",
       y="Count")
```


There are nine disciplines in which six medals were won. Since this far exceeds the other disciplines, the disciplines with six medals won will be excluded from the analysis. 


```{r}
discipline_outliers <- discipline_freq_new %>% 
  filter(frequency == 6) %>% 
  select(discipline_code)
```

```{r}
medals_data_trimmed %>% 
  filter(discipline_code %in% discipline_outliers$discipline_code)
```
### Create kNN data frame

- Remove outliers  

- Select attributes for kNN model


```{r}
medals_knn <- medals_data_trimmed %>% 
  filter(!(discipline_code %in% discipline_outliers$discipline_code)) %>% 
  select(medal_type, country_code, discipline_code, event)
```

```{r}
str(medals_knn)
```


### Create Decision Tree data frame

```{r}
medals_decision_tree <- medals_data_trimmed %>% 
  filter(!(discipline_code %in% discipline_outliers$discipline_code)) %>% 
  select(medal_type, country_code, discipline_code, event)
```

```{r}
str(medals_decision_tree)
```


## Data Transformation

Preprocess data for the K-Nearest Neighbors and Decision Tree models


### kNN data preparation

Convert the three categorical variables, country_code, discipline_code, and event into factors.  

```{r}
medals_knn$medal_type <- as.factor(medals_knn$medal_type)
medals_knn$country_code <- as.factor(medals_knn$country_code)
medals_knn$discipline_code <- as.factor(medals_knn$discipline_code)
medals_knn$event <- as.factor(medals_knn$event)
```


```{r}
summary(medals_knn)
```


#### Standardize columns for kNN

Standardize country_code, discipline_code, and event columns to have mean of zero and standard deviation of one


```{r}
medals_knn$country_code_int <- as.integer(medals_knn$country_code)
medals_knn$discipline_code_int <- as.integer(medals_knn$discipline_code)
medals_knn$event_int <- as.integer(medals_knn$event)
```

```{r}
medals_knn$country_code_scaled <- scale(medals_knn$country_code_int)
medals_knn$discipline_code_scaled <- scale(medals_knn$discipline_code_int)
medals_knn$event_scaled <- scale(medals_knn$event_int)
```

```{r summary medals_knn after scaling}
summary(medals_knn)
```

```{r}
colnames(medals_knn)
```


### Create binary columns for medal type column for Decision Tree data frame

```{r}
medals_decision_tree$gold <- ifelse(medals_decision_tree$medal_type == "Gold Medal", 1, 0)
medals_decision_tree$silver <- ifelse(medals_decision_tree$medal_type == "Silver Medal", 1, 0)
medals_decision_tree$bronze <- ifelse(medals_decision_tree$medal_type == "Bronze Medal", 1, 0)
```

```{r}
summary(medals_decision_tree)
```


## k-Nearest Neighbors Model

- Create training and test sets from medals_knn data frame where 80% of the data will be for training. The remaining 20% of the data will be for the test set

- Create k-Nearest Neighbors model for classification of medal types (Gold, Silver, and Bronze)


```{r}
shuffle_data <- function(medals.df) {
  # Set seed
  set.seed(42)

  # Shuffle row indices: rows
  rows <- sample(nrow(medals.df))

  # Randomly order data
  medals.df[rows,]
}
```

```{r}
shuffled_medals_knn <- shuffle_data(medals_knn)
```

```{r}
split <- round(nrow(shuffled_medals_knn)*0.80)
```

country_code_scaled    "discipline_code_scaled"
[10] "event_scaled"          

```{r}
medals_knn_train <- shuffled_medals_knn[1:split, c("medal_type", "country_code_scaled", "discipline_code_scaled", "event_scaled")]
```

```{r}
medals_knn_test <- shuffled_medals_knn[(split+1):nrow(shuffled_medals_knn),c("medal_type", "country_code_scaled", "discipline_code_scaled", "event_scaled")]
```


```{r}
medal_types.train <- medals_knn_train$medal_type
```

```{r}
p <- knn(train = medals_knn_train[-1], test = medals_knn_test[-1], cl = medal_types.train, k=3)
```

### Confusion matrix for kNN model

```{r}
table(medals_knn_test$medal_type, p)
```


### Compute accuracy of kNN model

```{r}
mean(p == medals_knn_test$medal_type)
```


### Calculate misclassification rate of kNN model

```{r}
num.incorrect <- sum(p != medals_knn_test$medal_type)
num.correct <- sum(p == medals_knn_test$medal_type)
```

```{r}
misclassification.rate <- num.incorrect / num.correct
```

```{r}
misclassification.rate
```


## Decision Tree Model

- Create training and test data sets in which 80% of the data will be for training.  The remainig 20% will be for the test set.

- Create Decision Tree model for a binary classification of Gold medals won


```{r}
shuffled_medals_dtree <- shuffle_data(medals_decision_tree)
```

```{r}
split.dtree <- round(nrow(shuffled_medals_dtree)*0.80)
```

```{r}
medals_dtree_train <- shuffled_medals_dtree[1:split,]
medals_dtree_test <- shuffled_medals_dtree[(split+1):nrow(shuffled_medals_dtree),]
```


```{r}
gold_model <- rpart(gold ~ country_code + discipline_code + event, data = medals_dtree_train, method = "class", control = rpart.control(cp = 0))
```

```{r Prediction on the test data set}
medals_dtree_test$pred <- predict(gold_model, medals_dtree_test, type = "class")
```

### Confusion matrix for Decision Tree model

```{r}
table(medals_dtree_test$gold, medals_dtree_test$pred)
```

### Calculate accuracy score for Decision Tree model

```{r}
mean(medals_dtree_test$gold == medals_dtree_test$pred)
```

### Calculate misclassification rate for Decision Tree model

```{r}
num.incorrect.dtree <- sum(medals_dtree_test$gold != medals_dtree_test$pred)
num.correct.dtree <- sum(medals_dtree_test$gold)
misclassification.rate.dtree <- num.incorrect.dtree / num.correct.dtree
```


## Cross-Validation

### kNN Cross-Validation


```{r}
cv_knn_model <- train(medal_type ~ ., data = medals_knn_train, 
                      method = "knn",
                      trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE))
```

```{r}
cv_knn_model
```


### Decision tree Cross-Validation


```{r}
cv_dtree_model <- train(gold ~ country_code + discipline_code + event, 
                        data = medals_dtree_train, 
                        method = "rpart",
                        trControl = trainControl(method = "cv", number = 5, verboseIter = TRUE))
```

```{r}
cv_dtree_model
```



## References

k-Nearest Neighbor: An Introductory Example.
https://quantdev.ssri.psu.edu/sites/qdev/files/kNN_tutorial.html

