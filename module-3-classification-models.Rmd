---
title: "module-3-assignment"
output: html_document
date: '2022-05-23'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Overview

1. Create Decision Tree and KNN classifiers on a data set without cross validation. 

2. Then using cross-validation create classification decision tree and KNN models on same data set.  

Compare results between first two cases:

- Which classifier was more accurate?

- Which strategy performed best? cross-validation or without cross-validation?

- What statistic was used to compare performance


## Data Set

This is an Olympic Games dataset that describes medals and athletes for Tokyo 2020. The data was created from the [Tokyo Olympics](https://olympics.com/tokyo-2020/en/). More than 2,400 medals, and 11,000 athletes (with some personal data: date and place of birth, height, etc.) of the XXXII Olympic Games you can find here. Apart from it coaches and technical officials are present. 

The medals.csv file was downloaded from Kaggle at https://www.kaggle.com/datasets/piterfm/tokyo-2020-olympics?select=medals.csv. 

**Author of Data Set:**

Petro
Kaggle Expert
Lviv, Lviv Oblast, Ukraine
Data Scientist, PhD

## R Libraries

```{r echo=FALSE, warning=FALSE, message=FALSE}
library(tidyverse)
library(skimr)
library(janitor)
```
```{r}
library(class)
```



## Read CSV file

```{r}
medals_data <- read.csv('data/medals.csv')
```

```{r}
str(medals_data)
```

## Data Cleaning

```{r}
skim_without_charts(medals_data)
```

```{r}
medals_data_trimmed <- medals_data %>% 
  select(medal_type, country_code, discipline_code, event)
```

```{r}
head(medals_data_trimmed)
```
```{r}
distinct_discipline <- medals_data %>% 
  select(c(discipline_code, discipline)) %>% 
  unique()
```


### Aggregate by event, country_code, discipline_code

```{r}
medals_summary <- medals_data_trimmed %>% 
  group_by(country_code, discipline_code, event) %>% 
  summarise(medal_label = max(medal_type))
```

```{r}
head(medals_summary)
```

## Data Transformation

- Preprocess data for the K-Nearest Neighbors model

- Preprocess data for the Decision Tree model

### Convert categorical columns into factors

Convert the three categorical variables, country_code, discipline_code, and event into factors.  


```{r}
medals_summary$country_code <- as.factor(medals_summary$country_code)
medals_summary$discipline_code <- as.factor(medals_summary$discipline_code)
medals_summary$event <- as.factor(medals_summary$event)
```

```{r}
str(medals_summary)
```

```{r glimpse medals_summary}
glimpse(medals_summary)
```
```{r}
str(medals_summary)
```


### Check for Outliers

```{r contigency table discipline_code}
discipline_code_freq <- table(medals_summary$discipline_code) %>% as.data.frame %>% arrange(Freq)
```

```{r}
merge(discipline_code_freq, distinct_discipline, by.x = 'Var1', by.y = 'discipline_code', all.x = TRUE) %>% 
  arrange(Freq)
```
```{r}
medals_summary %>% 
  filter(discipline_code=='MTB')
```
The disciplines with lower frequencies have fewer medals won. The Cycling Mountain Bike discipline has two  events with four medals won.  The disciplines with frequencies below ten will be considered outliers.

```{r}
discipline_code_outliers <- discipline_code_freq %>% 
  filter(Freq<10)
```

```{r}

```




```{r}
ggplot(data = medals_summary) +
  geom_bar(mapping = aes(x = discipline_code)) +
  facet_wrap(~medal_label)
  labs(title="Olympic events",
       caption=paste0("Data from: 2020 Tokyo Olympics"),
       x="Discipline",
       y="Count")
```

```{r}

```




## References

k-Nearest Neighbor: An Introductory Example.
https://quantdev.ssri.psu.edu/sites/qdev/files/kNN_tutorial.html

